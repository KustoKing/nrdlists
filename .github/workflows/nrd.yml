name: âœ¨ Update NRD Lists

on:
  schedule:
    - cron: "7 */2 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
    - name: âœ… Checkout Repository
      uses: actions/checkout@v4

    - name: â˜• Install Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y unzip curl coreutils moreutils

    - name: ğŸ“ Download NRD, Entropy, and Phishing Feeds (with Retry)
      env:
        NRD_30:        ${{ secrets.STAMUS_NRD_30_URL }}
        ENTROPY_30:    ${{ secrets.STAMUS_ENTROPY_30_URL }}
        PHISHING_30:   ${{ secrets.STAMUS_PHISHING_30_URL }}
        NRD_14:        ${{ secrets.STAMUS_NRD_14_URL }}
        ENTROPY_14:    ${{ secrets.STAMUS_ENTROPY_14_URL }}
        PHISHING_14:   ${{ secrets.STAMUS_PHISHING_14_URL }}
      run: |
        set -euo pipefail
        mkdir -p feeds
        download() {
          local url=$1
          local dest=$2
          local retries=3
          for i in $(seq 1 $retries); do
            echo "â” Attempt $i to download $url"
            if curl -fsSLo "$dest" "$url"; then
              echo "âœ… Downloaded $dest"
              date -R -r "$dest" > "$dest.timestamp"
              return 0
            else
              echo "âš ï¸ Failed attempt $i for $url"
              sleep 2
            fi
          done
          echo "âŒ All retries failed for $url"
          return 1
        }

        download "$NRD_30" feeds/nrd-30.tar.gz
        download "$ENTROPY_30" feeds/entropy-30.tar.gz
        download "$PHISHING_30" feeds/phishing-30.tar.gz
        download "$NRD_14" feeds/nrd-14.tar.gz
        download "$ENTROPY_14" feeds/entropy-14.tar.gz
        download "$PHISHING_14" feeds/phishing-14.tar.gz

    - name: ğŸ“¦ Extract Archives
      run: |
        mkdir -p extracted
        for file in feeds/*.tar.gz; do
          tar -xzf "$file" -C extracted/
        done

    - name: ğŸš– Organize and Standardize Extracted Lists
      run: |
        mkdir -p lists/{14-day,30-day}/{domains-only,high-entropy,phishing/domains-only}
        cp extracted/rules/nrd-30day              lists/30-day/domains-only/nrd-30day.txt || true
        cp extracted/rules/nrd-entropy-30day      lists/30-day/high-entropy/nrd-entropy-30day.txt || true
        cp extracted/rules/nrd-phishing-30day     lists/30-day/phishing/domains-only/nrd-phishing-30day.txt || true
        cp extracted/rules/nrd-14day              lists/14-day/domains-only/nrd-14day.txt || true
        cp extracted/rules/nrd-entropy-14day      lists/14-day/high-entropy/nrd-entropy-14day.txt || true
        cp extracted/rules/nrd-phishing-14day     lists/14-day/phishing/domains-only/nrd-phishing-14day.txt || true

    - name: ğŸ” Decode Base64 Lines in Standardized Lists (with Benchmark)
      run: |
        set -euo pipefail
        for file in $(find lists -type f -name '*.txt'); do
          if [ $(wc -l < "$file") -eq 0 ]; then
            echo "âš ï¸ Skipping empty file: $file"
            continue
          fi
          echo "ğŸ“œ Decoding $file ($(wc -l < "$file") lines)"
          start=$(date +%s)
          awk '{ print | "base64 -d 2>/dev/null" }' "$file" > "$file.decoded" || echo "âš ï¸ Warning: decoding failed for $file"
          mv "$file.decoded" "$file"
          end=$(date +%s)
          echo "â±ï¸ Done in $((end - start))s"
        done

    - name: âš–ï¸ Compare File Hashes
      run: |
        mkdir -p hash
        for file in $(find lists -type f -name '*.txt'); do
          sha256sum "$file" | cut -d ' ' -f1 > "hash/current_$(basename "$file")"
        done

    - name: âŒ Abort if No Changes
      run: |
        if git diff --quiet --exit-code hash; then
          echo "âŒ No changes detected. Exiting."
          exit 0
        fi

    - name: ğŸ” Apply TLD and Top-1M Filtering
      run: |
        set -euo pipefail
        curl -fsSLo iana-tlds.txt https://data.iana.org/TLD/tlds-alpha-by-domain.txt
        awk '{print tolower($0)}' iana-tlds.txt > iana-tlds.tmp && mv iana-tlds.tmp iana-tlds.txt
        for file in $(find lists -name '*.txt'); do
          grep -vFxf iana-tlds.txt "$file" > "$file.tmp" && mv "$file.tmp" "$file"
        done

        mkdir -p top1m
        curl -fsSLo top1m/umbrella.zip https://s3-us-west-1.amazonaws.com/umbrella-static/top-1m.csv.zip || true
        curl -fsSLo top1m/tranco.zip https://tranco-list.eu/download/daily/top-1m.csv.zip || true

        unzip -jo top1m/umbrella.zip '*.csv' -d top1m/ || true
        unzip -jo top1m/tranco.zip '*.csv' -d top1m/ || true

        awk -F, 'NR>1 && $2 ~ /^[a-zA-Z0-9.-]+$/ { print $2 }' top1m/*umbrella*.csv > top1m/umbrella.txt || true
        awk -F, 'NR>1 && $2 ~ /^[a-zA-Z0-9.-]+$/ { print $2 }' top1m/*tranco*.csv > top1m/tranco.txt || true

        cat top1m/umbrella.txt top1m/tranco.txt | sort -u > top1m-blocklist.txt || true
        for file in $(find lists -name '*.txt'); do
          grep -vFxf top1m-blocklist.txt "$file" > "$file.tmp" && mv "$file.tmp" "$file"
        done

    - name: ğŸ’¥ Split Large Files (>90MB)
      run: |
        set -euo pipefail
        threshold=$((90 * 1024 * 1024))
        for file in $(find lists -name '*.txt'); do
          size=$(stat -c%s "$file")
          if [ "$size" -gt "$threshold" ]; then
            echo "ğŸš¨ Splitting $file (${size}B)"
            split --bytes=80MB --numeric-suffixes=1 --additional-suffix=.part.txt "$file" "$file."
            rm "$file"
            echo "ğŸ§¹ Removed original: $file"
          fi
        done

    - name: ğŸ“‹ Commit & Push Updates
      run: |
        set -euo pipefail
        git config user.name "KustoKing[bot]"
        git config user.email "gianni@kustoking.com"
        git fetch origin
        git stash --include-untracked || true
        git rebase origin/main || git pull --rebase
        git stash pop || true
        git add lists hash || true
        if ! git diff --cached --quiet; then
          git commit -m "ci: update NRD lists $(date +'%Y-%m-%d %H:%M')"
          git push
        else
          echo "âŒ Nothing to commit."
        fi

    - name: ğŸ“‚ Save Hashes for Next Run
      run: |
        mkdir -p hash
        for file in $(find lists -type f -name '*.txt'); do
          sha256sum "$file" | cut -d ' ' -f1 > "hash/current_$(basename "$file")"
        done

    - name: ğŸ“Š Summary & Metrics
      run: |
        echo "\nâœ¨ Summary Report"
        echo "========================="

        echo "\nğŸ“… Feed Modification Times:"
        for f in feeds/*.timestamp; do
          base=$(basename "$f" .timestamp)
          printf "%s: %s\n" "$base" "$(cat $f)"
        done

        echo "\nğŸ“ Feed Sizes:"
        for f in feeds/*.tar.gz; do
          [ -f "$f" ] && echo "$f: $(du -h "$f" | cut -f1)"
        done

        echo "\nğŸ” Line Counts in Final Lists:"
        find lists -type f -name '*.txt' | while read -r f; do
          echo "$f: $(wc -l < "$f") lines"
        done

        echo "\nğŸ” Top-1M Domains Blocked:"
        echo "Top-1M Combined List: $(wc -l < top1m-blocklist.txt 2>/dev/null || echo 0) entries"
        echo "TLDs Filtered: $(wc -l < iana-tlds.txt 2>/dev/null || echo 0) entries"
        echo "========================="
