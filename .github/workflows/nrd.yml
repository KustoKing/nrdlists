name: Update NRD List

on:
  schedule:
    - cron: "7 */2 * * *"  # Every 2 hours at 07 minutes past
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true

jobs:
  update-nrd-list:
    runs-on: ubuntu-latest

    steps:
      - name: üìã Checkout Repository
        uses: actions/checkout@v3

      - name: üõ†Ô∏è Install Dependencies
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y unzip curl coreutils

      - name: üì• Download NRD, Entropy, and Phishing Feeds
        env:
          STAMUS_NRD_30_URL: ${{ secrets.STAMUS_NRD_30_URL }}
          STAMUS_ENTROPY_30_URL: ${{ secrets.STAMUS_ENTROPY_30_URL }}
          STAMUS_PHISHING_30_URL: ${{ secrets.STAMUS_PHISHING_30_URL }}
          STAMUS_NRD_14_URL: ${{ secrets.STAMUS_NRD_14_URL }}
          STAMUS_ENTROPY_14_URL: ${{ secrets.STAMUS_ENTROPY_14_URL }}
          STAMUS_PHISHING_14_URL: ${{ secrets.STAMUS_PHISHING_14_URL }}
        run: |
          set -euo pipefail
          mkdir -p downloads
          curl -fsS -o downloads/nrd-30.tar.gz "$STAMUS_NRD_30_URL"
          curl -fsS -o downloads/entropy-30.tar.gz "$STAMUS_ENTROPY_30_URL"
          curl -fsS -o downloads/phishing-30.tar.gz "$STAMUS_PHISHING_30_URL"
          curl -fsS -o downloads/nrd-14.tar.gz "$STAMUS_NRD_14_URL"
          curl -fsS -o downloads/entropy-14.tar.gz "$STAMUS_ENTROPY_14_URL"
          curl -fsS -o downloads/phishing-14.tar.gz "$STAMUS_PHISHING_14_URL"

      - name: üì¶ Extract Archives
        run: |
          set -euo pipefail
          mkdir -p extracted
          for f in downloads/*.tar.gz; do
            tar -xzf "$f" -C extracted
          done
          rm -rf downloads

      - name: üì° Organize and Standardize Extracted Lists
        run: |
          set -euo pipefail
          mkdir -p lists/14-day/domains-only lists/30-day/domains-only
          mkdir -p lists/14-day/high-entropy lists/30-day/high-entropy
          mkdir -p lists/14-day_phishing/domains-only lists/30-day_phishing/domains-only

          move_if_exists() {
            src=$1; dest=$2; name=$3
            if [[ -f "$src" ]]; then
              cp "$src" "$dest/$name.txt"
            else
              echo "‚ö†Ô∏è Missing: $src"
            fi
          }

          move_if_exists extracted/rules/nrd-14day              lists/14-day/domains-only          nrd-14day
          move_if_exists extracted/rules/nrd-30day              lists/30-day/domains-only          nrd-30day
          move_if_exists extracted/rules/nrd-entropy-14day      lists/14-day/high-entropy          nrd-entropy-14day
          move_if_exists extracted/rules/nrd-entropy-30day      lists/30-day/high-entropy          nrd-entropy-30day
          move_if_exists extracted/rules/nrd-phishing-14day     lists/14-day_phishing/domains-only nrd-phishing-14day
          move_if_exists extracted/rules/nrd-phishing-30day     lists/30-day_phishing/domains-only nrd-phishing-30day

          rm -rf extracted

      - name: üîì Decode Base64 Lines in Standardized Lists
        run: |
          set -euo pipefail
          for file in $(find lists -name '*.txt'); do
            echo "üì• Decoding Base64 (line-by-line) in $file"
            {
              while IFS= read -r line; do
                echo "$line" | base64 -d 2>/dev/null || echo "‚ö†Ô∏è Base64 decode failed"
              done
            } < "$file" > "$file.decoded"
            mv "$file.decoded" "$file"
          done

      - name: üîç Compare File Hashes
        id: hashcheck
        run: |
          set -euo pipefail
          mkdir -p hash
          CHANGED=0

          for path in lists/*/*/*.txt; do
            [ -f "$path" ] || { echo "‚ùå Missing: $path"; CHANGED=1; continue; }
            name=$(basename "$path" .txt)
            sha256sum "$path" > "hash/current_$name.txt"
            if [[ ! -f "hash/previous_$name.txt" ]] || ! cmp -s "hash/previous_$name.txt" "hash/current_$name.txt"; then
              echo "‚ûï Changed: $name"
              CHANGED=1
            fi
          done

          echo "changed=$CHANGED" >> $GITHUB_ENV

      - name: ‚ùå Abort if No Changes
        if: env.changed == '0'
        run: echo "No changes detected. Workflow exiting."

      - name: ü™§ Apply TLD and Top-1M Filtering
        if: env.changed != '0'
        run: |
          set -euo pipefail

          curl -fsS -O https://data.iana.org/TLD/tlds-alpha-by-domain.txt
          awk '{print tolower($0)}' tlds-alpha-by-domain.txt > iana-tlds.txt
          for file in lists/*/*/*.txt; do
            grep -vFxf iana-tlds.txt "$file" > "$file.tmp" && mv "$file.tmp" "$file"
          done

          mkdir -p top1m

          download_or_skip() {
            name="$1"; url="$2"; output="$3"
            echo "üåê Downloading $name..."
            if curl -fsSL --retry 3 --create-dirs -o "$output" "$url"; then
              echo "‚úÖ $name downloaded."
            else
              echo "‚ö†Ô∏è $name download failed: $url"
              touch "$output"
            fi
          }

          download_or_skip "Umbrella"  "https://s3-us-west-1.amazonaws.com/umbrella-static/top-1m.csv.zip" "top1m/umbrella.zip"
          download_or_skip "BuiltWith" "https://builtwith.com/dl/builtwith-top1m.zip" "top1m/builtwith.zip"
          download_or_skip "Tranco"    "https://tranco-list.eu/download/daily/top-1m.csv.zip" "top1m/tranco.zip"

          ls -lh top1m/*.zip || echo "üìÜ No zip files to extract"

          unzip -jo top1m/umbrella.zip '*.csv' -d top1m/ || true
          unzip -jo top1m/builtwith.zip '*.csv' -d top1m/ || true
          unzip -jo top1m/tranco.zip '*.csv' -d top1m/ || true

          awk -F, '{print $2}' top1m/*umbrella*.csv > top1m/umbrella.txt || true
          awk -F, '{print $2}' top1m/*builtwith*.csv > top1m/builtwith.txt || true
          awk -F, '{print $2}' top1m/*tranco*.csv > top1m/tranco.txt || true

          cat top1m/*.txt | sort -u > top1m-blocklist.txt || touch top1m-blocklist.txt

          for file in lists/*/*/*.txt; do
            grep -vFxf top1m-blocklist.txt "$file" > "$file.tmp" && mv "$file.tmp" "$file"
          done

          rm -rf top1m iana-tlds.txt tlds-alpha-by-domain.txt

      - name: üí• Split Large Files (>90MB)
        if: env.changed != '0'
        run: |
          set -euo pipefail
          threshold=$((90 * 1024 * 1024))
          for file in $(find lists -name '*.txt'); do
            size=$(stat -c%s "$file")
            if [ "$size" -gt "$threshold" ]; then
              echo "üö® Splitting $file ($size bytes)"
              split --bytes=80MB --numeric-suffixes=1 --additional-suffix=.part.txt "$file" "$file."
              rm "$file"
            fi
          done

      - name: üöÄ Commit & Push Updates
        if: env.changed != '0'
        run: |
          set -euo pipefail
          git config user.name "KustoKing[bot]"
          git config user.email "gianni@kustoking.com"
          git add lists || true
          ls hash/current_*.txt 2>/dev/null && git add hash/current_*.txt || true
          if ! git diff --cached --quiet; then
            git commit -m "ci: update NRD lists $(date +'%Y-%m-%d %H:%M')"
            git push
          else
            echo "Nothing to commit."
          fi

      - name: üíæ Save Hashes for Next Run
        if: env.changed != '0'
        run: |
          set -euo pipefail
          for path in hash/current_*.txt; do
            name=$(basename "$path")
            mv "$path" "hash/previous_${name#current_}"
          done
          git add hash/previous_*.txt || true
          if ! git diff --cached --quiet; then
            git commit -m "ci: update saved hashes"
            git push
          else
            echo "Hash files unchanged."
          fi
